# inject a packet delay of 0-90ms while increasing the otel metric inverval to 1s
experiment:
  version: 0.0.1
  orchestrator: kubernetes
  services:
    jaeger: 
      name: astronomy-shop-jaeger-query
      namespace: system-under-evaluation
    prometheus: [
      { name: astronomy-shop-prometheus-server, namespace: system-under-evaluation, target: sue },
      { name: kube-prometheus-kube-prome-prometheus, namespace: oxn-external-monitoring, target: oxn },
    ]
  responses:
    - frontend_traces:
        type: trace
        service_name: frontend 
        left_window: 240s
        right_window: 240s
        limit: 10000
    - recommendation_traces:
        type: trace
        service_name: recommendationservice 
        left_window: 240s
        right_window: 240s
        limit: 10000
    - system_CPU:
        type: metric
        metric_name: sum(rate(container_cpu_usage_seconds_total{namespace="system-under-evaluation"}[1m]))
        left_window: 240s
        right_window: 240s
        step: 1
        target: oxn
    - recommendation_deployment_CPU:
        type: metric
        metric_name: sum(rate(container_cpu_usage_seconds_total{namespace="system-under-evaluation", pod=~"astronomy-shop-recommendationservice.*"}[90s])) by (pod)
        left_window: 240s
        right_window: 240s
        step: 1
        target: oxn
    - recommendationservice_kepler_package_joules:
        type: metric
        metric_name: sum by (pod_name, container_namespace) (irate(kepler_container_package_joules_total{container_namespace=~"system-under-evaluation", pod_name=~"astronomy-shop-recommendationservice.*"}[1m]))
        left_window: 240s
        right_window: 240s
        step: 1
        target: oxn
    - recommendationservice_kepler_dram_joules:
        type: metric
        metric_name: sum by (pod_name, container_namespace) (irate(kepler_container_dram_joules_total{container_namespace=~"system-under-evaluation", pod_name=~"astronomy-shop-recommendationservice.*"}[1m]))
        left_window: 240s
        right_window: 240s
        step: 1
        target: oxn
    - recommendationservice_kepler_other_joules:
        type: metric
        metric_name: sum by (pod_name, container_namespace) (irate(kepler_container_other_joules_total{container_namespace=~"system-under-evaluation", pod_name=~"astronomy-shop-recommendationservice.*"}[1m]))
        left_window: 240s
        right_window: 240s
        step: 1
        target: oxn
    - latency_frontend_95_percentile:
        type: metric
        metric_name: histogram_quantile(0.95, sum(rate(duration_milliseconds_bucket{service_name="frontend"}[90s])) by (le))
        left_window: 240s
        right_window: 240s
        step: 1
        target: sue
    - latency_recommendationservice_95_percentile:
        type: metric
        metric_name: histogram_quantile(0.95, sum(rate(duration_milliseconds_bucket{service_name="recommendationservice"}[90s])) by (le))
        left_window: 240s
        right_window: 240s
        step: 1
        target: sue
    - recommendations_total:
        type: metric
        metric_name: increase(app_recommendations_counter_total[1m])
        left_window: 240s
        right_window: 240s
        step: 1
        target: sue
    - sampling_rates:
        type: metric
        metric_name: increase(otelcol_processor_probabilistic_sampler_count_traces_sampled[1m])
        left_window: 240s
        right_window: 240s
        step: 1
        target: sue
  treatments:
    #- kill_recommendation_service:
    #    action: kubernetes_kill
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/component,
    #      label: recommendationservice,
    #      amount_to_kill: 1,
    #    }
    #- stop_loadgen_deployment:
    #    action: scale_deployment
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/component,
    #      label: loadgenerator,
    #      scale_to: 0,
    #    }
    #- add_security_context:
    #    action: security_context_kubernetes
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/component,
    #      label: recommendationservice,
    #      capabilities: { add: ["NET_ADMIN"] },
    #    }
    - delay_treatment:
        action: delay
        params: {
          namespace: system-under-evaluation,
          label_selector: app.kubernetes.io/name,
          label: astronomy-shop-recommendationservice,
          #service_name: node-exporter,
          delay_time: 45ms,
          delay_jitter: 45ms,
          duration: 10m,
          interface: eth0,
        }
    - probabilistic_head_sampling_rate:
        action: kube_probl
        params: {
          sampling_percentage: 5.0,
          hash_seed: 22,
          }
    # - interval:
    #     action: otel_metrics_interval
    #     params: {
    #       compose_file: opentelemetry-demo/docker-compose.yml,
    #       service_name: recommendationservice,
    #       interval: 1s
    #     }
    #- increase_otel_metric_interval:
    #    action: kubernetes_otel_metrics_interval
    #    params: {
    #      namespace: system-under-evaluation,
    #      label_selector: app.kubernetes.io/component,
    #      label: recommendationservice,
    #      interval: 15s,
    #    }
     #reloading the prometheus config is not as trivial as it seems to be
    #- prometheus_scrape_interval:
    #    action: kubernetes_prometheus_interval
    #    params: {
    #      interval: 5s,
    #      evaluation_interval: 5s,
    #      scrape_timeout: 3s,
    #    }
  sue:
    compose: opentelemetry-demo/docker-compose.yml
    exclude: [loadgenerator]
    required: [{namespace: system-under-evaluation, name: astronomy-shop-prometheus-server}] # {namespace: monitoring, name: not-running-service}
    #required: [{namespace: monitoring, name: grafana}, {namespace: monitoring, name: node-exporter}]
  loadgen:
    run_time: 15m
    #stages: 
    #- {duration: 20, users: 10, spawn_rate: 5}
    #- {duration: 600, users: 50, spawn_rate: 10}
    #tasks:
    #- { endpoint: /, verb: get, weight: 1, params: { } }
    #- { endpoint: /api/products/0PUK6V6EV0, verb: get, weight: 10, params: { } }
    #- { endpoint: /api/recommendations, verb: get, weight: 3, params: { "productIds": ["1YMWWN1N4O"]}}
    #- { endpoint: /api/cart, verb: get, weight: 3, params: { } }
    #- { endpoint: /api/data, verb: get, weight: 3, params: { "contextKeys": [ "accessories" ] } }
    #- { endpoint: /api/cart, verb: post, weight: 2, params: { "item": {"productId":"6E92ZMYYFZ", "quantity":2, }, "userId":'ab2d0fc0-7224-11ec-8ef2-b658b885fb3',} }
    locust_files: [
      { path: locust/locust_basic_interaction.py },
      { path: locust/locust_otel_demo.py },
      ]
    target:
      name: astronomy-shop-frontendproxy
      namespace: system-under-evaluation
      port: 8080