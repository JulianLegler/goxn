# inject a packet delay of 0-90ms while increasing the otel metric inverval to 1s
experiment:
  version: 0.0.1
  orchestrator: kubernetes
  pods:
    jaeger: 
      label_selector: app.kubernetes.io/name
      label: jaeger
      namespace: default
    prometheus:
      label_selector: app.kubernetes.io/name
      label: prometheus
      namespace: default
  responses:
    - frontend_traces:
        type: trace
        service_name: frontend 
        left_window: 240s 
        right_window: 240s 
        limit: 100000
    - recommendation_traces:
        type: trace
        service_name: recommendationservice 
        left_window: 240s 
        right_window: 240s 
        limit: 100000
    - system_CPU:
        type: metric
        metric_name: sum(rate(container_cpu_usage_seconds_total{container_label_com_docker_compose_project="opentelemetry-demo"}[1m]))
        left_window: 240s 
        right_window: 240s
        step: 1
    - recommendations_total:
        type: metric
        metric_name: increase(app_recommendations_counter_total[90s])
        left_window: 240s 
        right_window: 240s
        step: 1
  treatments:
    - kill_recommendation_service:
        action: kubernetes_kill
        params: {
          namespace: default,
          label_selector: app.kubernetes.io/component,
          label: recommendationservice,
          amount_to_kill: 1,
        }
    - stop_loadgen_deployment:
        action: scale_deployment
        params: {
          namespace: default,
          label_selector: app.kubernetes.io/component,
          label: loadgenerator,
          scale_to: 0,
        }
    - add_security_context:
        action: security_context_kubernetes
        params: {
          namespace: default,
          label_selector: app.kubernetes.io/component,
          label: recommendationservice,
          capabilities: { add: ["NET_ADMIN"] },
        }
    #- delay_treatment:
    #    action: delay
    #    params: {
    #      namespace: default,
    #      label_selector: app.kubernetes.io/component,
    #      label: recommendationservice,
    #      #service_name: node-exporter,
    #      delay_time: 45ms,
    #      delay_jitter: 45ms,
    #      duration: 60s,
    #      interface: eth0,
    #    }
    - interval:
        action: otel_metrics_interval
        params: {
          compose_file: opentelemetry-demo/docker-compose.yml,
          service_name: recommendationservice,
          interval: 1s
        }
  sue:
    compose: opentelemetry-demo/docker-compose.yml
    exclude: [loadgenerator]
    required: [{namespace: monitoring, name: grafana}, {namespace: monitoring, name: node-exporter}] # {namespace: monitoring, name: not-running-service}
    #required: [{namespace: monitoring, name: grafana}, {namespace: monitoring, name: node-exporter}]
  loadgen:
    run_time: 10m
    #stages: 
    #- {duration: 20, users: 10, spawn_rate: 5}
    #- {duration: 600, users: 50, spawn_rate: 10}
    #tasks:
    #- { endpoint: /, verb: get, weight: 1, params: { } }
    #- { endpoint: /api/products/0PUK6V6EV0, verb: get, weight: 10, params: { } }
    #- { endpoint: /api/recommendations, verb: get, weight: 3, params: { "productIds": ["1YMWWN1N4O"]}}
    #- { endpoint: /api/cart, verb: get, weight: 3, params: { } }
    #- { endpoint: /api/data, verb: get, weight: 3, params: { "contextKeys": [ "accessories" ] } }
    #- { endpoint: /api/cart, verb: post, weight: 2, params: { "item": {"productId":"6E92ZMYYFZ", "quantity":2, }, "userId":'ab2d0fc0-7224-11ec-8ef2-b658b885fb3',} }
    locust_files: [
      { path: locust/locust_basic_interaction.py },
      { path: locust/locust_otel_demo.py },
      ]
    target:
      label_selector: app.kubernetes.io/component
      label: frontendproxy
      namespace: default
      port: 8080